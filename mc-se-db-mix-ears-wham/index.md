# Multi-Channel Speech Enhancement Database: Mixing EARS and WHAM

## Database of clean and noisy speech samples

We present samples from the database we developed to train and evaluate multi-channel speech enhancement methods.
This database was created using the [`Python`](https://www.python.org/) programming language and the [`pyroomacoustics`](https://pyroomacoustics.readthedocs.io/) library.

We mixed clean-speech audio signals from the Expressive Anechoic Recordings of Speech ([EARS](https://sp-uhh.github.io/ears_dataset/)) dataset, and ambient-noise audio signals from the WSJ0 Hipster Ambient Mixtures ([WHAM!](http://wham.whisper.ai)) dataset.


Audio files were originally created with $M=4$ channels.
However, here, we report signals with only $M=2$ channels, in order for the listener to assess the stereophonic properties of the signals.

## Sample 1 
SNR, SIR

## Sample 2 
SNR, SIR

## Sample 3
SNR, SIR